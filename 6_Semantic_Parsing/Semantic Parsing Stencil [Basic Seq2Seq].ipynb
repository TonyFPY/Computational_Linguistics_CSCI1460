{"cells":[{"cell_type":"markdown","metadata":{"id":"_hfJFfYRSFBV"},"source":["# Data Pre-processing"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"6rE5Aih1yY_i","executionInfo":{"status":"ok","timestamp":1671475299053,"user_tz":300,"elapsed":4610,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}}},"outputs":[],"source":["# data from https://www.cs.utexas.edu/~ai-lab/pubs/cocktail-ecml-01.pdf\n","# and https://www.cs.utexas.edu/users/ml/nldata.html \n","\n","import regex as re\n","from nltk.stem import SnowballStemmer\n","from urllib.request import urlopen\n","from contextlib import closing\n","from sklearn.model_selection import train_test_split\n","\n","ss = SnowballStemmer('english')\n","\n","inputs = []\n","queries = []\n","\n","# Extract the raw data from the URL\n","with closing(urlopen('ftp://ftp.cs.utexas.edu/pub/mooney/nl-ilp-data/jobsystem/jobqueries640')) as r:\n","  for line in r.readlines():\n","    line = line.decode('utf-8')\n","    input, query = line.lower().split('],')\n","\n","    # parse input. lowercase, stem with nltk, add <s>\n","    input = input[7:-2].split(',')\n","    input = [ss.stem(x) for x in input]\n","    inputs.append(input)\n","\n","    # parse query \n","    query = query.strip('.\\n')\n","    # https://stackoverflow.com/questions/43092970/tokenize-by-using-regular-expressions-parenthesis\n","    query = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", query)\n","    query = [\"<s>\"] + query + [\"</s>\"]\n","    queries.append(query)\n","\n","# do train test split of 500 training and 140 test instances\n","inputs_train, inputs_test, queries_train, queries_test = train_test_split(inputs, queries, test_size=140, random_state=8)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1671475299053,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"},"user_tz":300},"id":"rqr9r3NTI-ab","outputId":"4e850530-9c79-4e3a-b530-8b79489d3f23"},"outputs":[{"output_type":"stream","name":"stdout","text":["['what', 'job', 'are', 'there', 'use', 'tcl/tk']\n","['<s>', 'answer', '(', '_1973', ',', '(', 'job', '(', '_1973', ')', ',', 'language', '(', '_1973', ',', '_1990', ')', ',', 'const', '(', '_1990', ',', \"'\", 'tcl', '/', 'tk', \"'\", ')', ')', ')', ')', '</s>']\n","['show', 'me', 'the', 'job', 'use', 'c++', 'that', 'requir', 'a', 'bscs', 'but', 'desir', 'a', 'mscs']\n","['<s>', 'answer', '(', 'c', ',', '(', 'job', '(', 'c', ')', ',', 'language', '(', 'c', ',', 'l', ')', ',', 'const', '(', 'l', ',', \"'\", 'c', '+', '+', \"'\", ')', ',', 'req_deg', '(', 'c', ',', 'd', ')', ',', 'const', '(', 'd', ',', \"'\", 'bscs', \"'\", ')', ',', 'des_deg', '(', 'c', ',', 'e', ')', ',', 'const', '(', 'e', ',', \"'\", 'mscs', \"'\", ')', ')', ')', ')', '</s>']\n","['what', 'job', 'are', 'there', 'for', 'a', 'network', 'specialist']\n","['<s>', 'answer', '(', '_3359', ',', '(', 'job', '(', '_3359', ')', ',', 'area', '(', '_3359', ',', '_3378', ')', ',', 'const', '(', '_3378', ',', \"'\", 'networking', \"'\", ')', ')', ')', ')', '</s>']\n","['give', 'me', 'the', 'job', 'in', 'visual', 'c++']\n","['<s>', 'answer', '(', '_5851', ',', '(', 'job', '(', '_5851', ')', ',', 'language', '(', '_5851', ',', '_5868', ')', ',', 'const', '(', '_5868', ',', \"'\", 'visual', 'c', '+', '+', \"'\", ')', ')', ')', ')', '</s>']\n","['list', 'job', 'requir', 'bsee']\n","['<s>', 'answer', '(', '_7125', ',', '(', 'job', '(', '_7125', ')', ',', 'req_deg', '(', '_7125', ',', '_7138', ')', ',', 'const', '(', '_7138', ',', \"'\", 'bsee', \"'\", ')', ')', ')', ')', '</s>']\n"]}],"source":["# Check the first 5 raw data\n","for i in range(5):\n","  print(inputs_train[i])\n","  print(queries_train[i])"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"KEG4r-BpA3mH","executionInfo":{"status":"ok","timestamp":1671475299054,"user_tz":300,"elapsed":15,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}}},"outputs":[],"source":["from collections import Counter\n","\n","input_vocab = Counter()\n","for l in inputs_train:\n","  input_vocab.update(l)\n","\n","# Update the input word2idx and idx2word\n","input_word2idx = {}\n","for w, c in input_vocab.items():\n","  if c >= 2:\n","    input_word2idx[w] = len(input_word2idx)\n","input_word2idx['<UNK>'] = len(input_word2idx) # Set the index for unkown word\n","input_word2idx['<PAD>'] = len(input_word2idx) # Set the index for padding word\n","input_idx2word = {i:word for word,i in input_word2idx.items()} # Build the idx2word based on word2idx\n","\n","input_vocab = list(input_word2idx.keys()) \n","\n","# Update the query word2idx and idx2word\n","query_vocab = Counter()\n","for q in queries_train:\n","  query_vocab.update(q)\n","query_vocab['<UNK>'] = 0 \n","query_vocab['<PAD>'] = 0\n","query_idx2word = {i:word for i, word in enumerate(query_vocab.keys())}\n","query_word2idx = {word:i for i, word in query_idx2word.items()}"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1671475299054,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"},"user_tz":300},"id":"0c_RivDrE0rY","outputId":"fe954575-4afe-47b9-f242-2c2c4752af0b"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('what', 0), ('job', 1), ('are', 2), ('there', 3), ('use', 4), ('show', 5), ('me', 6), ('the', 7), ('c++', 8), ('that', 9)]\n","[(0, 'what'), (1, 'job'), (2, 'are'), (3, 'there'), (4, 'use'), (5, 'show'), (6, 'me'), (7, 'the'), (8, 'c++'), (9, 'that')]\n","[('<s>', 0), ('answer', 1), ('(', 2), ('_1973', 3), (',', 4), ('job', 5), (')', 6), ('language', 7), ('_1990', 8), ('const', 9)]\n","[(0, '<s>'), (1, 'answer'), (2, '('), (3, '_1973'), (4, ','), (5, 'job'), (6, ')'), (7, 'language'), (8, '_1990'), (9, 'const')]\n"]}],"source":["# Check the first 5 word2idx, idx2word\n","print(list(input_word2idx.items())[:10])\n","print(list(input_idx2word.items())[:10])\n","print(list(query_word2idx.items())[:10])\n","print(list(query_idx2word.items())[:10])"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"6NH1EXAqDgnR","executionInfo":{"status":"ok","timestamp":1671475299055,"user_tz":300,"elapsed":12,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}}},"outputs":[],"source":["# Feature Construction\n","inputs_train_tokens = [[input_word2idx.get(w, input_word2idx['<UNK>']) for w in l] for l in inputs_train]\n","inputs_test_tokens = [[input_word2idx.get(w, input_word2idx['<UNK>']) for w in l] for l in inputs_test]\n","\n","queries_train_tokens = [[query_word2idx.get(w, query_word2idx['<UNK>']) for w in l] for l in queries_train]\n","queries_test_tokens = [[query_word2idx.get(w, query_word2idx['<UNK>']) for w in l] for l in queries_test]\n","\n","# Add paddings to each feature\n","def pad(input_seq, max_len, pad_token_idx):\n","  input_seq = input_seq[:max_len]\n","  padded_seq = input_seq + (max_len - len(input_seq)) * [pad_token_idx]\n","  return padded_seq\n","\n","inputs_max_target_len = max([len(i) for i in inputs_train_tokens])\n","inputs_train_tokens = [pad(i, inputs_max_target_len, input_word2idx['<PAD>']) for i in inputs_train_tokens]\n","inputs_test_tokens = [pad(i, inputs_max_target_len, input_word2idx['<PAD>']) for i in inputs_test_tokens]\n","\n","queries_max_target_len = int(max([len(i) for i in queries_train_tokens]) * 1.5) \n","queries_train_tokens = [pad(i, queries_max_target_len, query_word2idx['<PAD>']) for i in queries_train_tokens]\n","queries_test_tokens = [pad(i, queries_max_target_len, query_word2idx['<PAD>']) for i in queries_test_tokens]"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1671475299055,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"},"user_tz":300},"id":"Y_WHbv05FzfS","outputId":"b878a553-293f-4e08-e0c3-13af89fd7317"},"outputs":[{"output_type":"stream","name":"stdout","text":["501 22 [0, 1, 2, 3, 4, 227, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228]\n","140 22 [2, 3, 48, 1, 20, 227, 227, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228]\n","501 166 [0, 1, 2, 3, 4, 2, 5, 2, 3, 6, 4, 7, 2, 3, 4, 8, 6, 4, 9, 2, 8, 4, 10, 11, 12, 13, 10, 6, 6, 6, 6, 14, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502]\n","140 166 [0, 1, 2, 501, 4, 2, 5, 2, 501, 6, 4, 25, 2, 501, 4, 501, 6, 4, 9, 2, 501, 4, 10, 206, 12, 207, 10, 6, 6, 6, 6, 14, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502]\n"]}],"source":["# Check the first 5 train, test tokens\n","# Print the number of tokens, feature length, the first feature\n","print(len(inputs_train_tokens), len(inputs_train_tokens[0]), inputs_train_tokens[0])\n","print(len(inputs_test_tokens), len(inputs_test_tokens[0]), inputs_test_tokens[0])\n","print(len(queries_train_tokens), len(queries_train_tokens[0]), queries_train_tokens[0])\n","print(len(queries_test_tokens), len(queries_test_tokens[0]), queries_test_tokens[0])"]},{"cell_type":"markdown","metadata":{"id":"RCKjb4HsMKw-"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"PginNNZ2sqqN","executionInfo":{"status":"ok","timestamp":1671475303444,"user_tz":300,"elapsed":4399,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}}},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader, default_collate\n","\n","class JobsDataset(Dataset):\n","  def __init__(self, inputs, queries):\n","    self.inputs = inputs\n","    self.queries = queries\n","\n","  def __len__(self):\n","      return len(self.inputs)\n","\n","  def __getitem__(self, idx):\n","      return self.inputs[idx], self.queries[idx]\n","\n","def build_datasets():\n","  jobs_train = JobsDataset(inputs=inputs_train_tokens, queries=queries_train_tokens)\n","  jobs_test = JobsDataset(inputs=inputs_test_tokens, queries=queries_test_tokens)\n","  return jobs_train, jobs_test\n","\n","def collate(batch):\n","  src, tgt = default_collate(batch)\n","  return torch.stack(src), torch.stack(tgt)\n","\n","def build_dataloaders(dataset_train, dataset_test, train_batch_size):\n","  dataloader_train = DataLoader(dataset_train, batch_size=train_batch_size, shuffle=True, collate_fn=collate)\n","  dataloader_test = DataLoader(dataset_test, batch_size=1, shuffle=False, collate_fn=collate)\n","  return dataloader_train, dataloader_test"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1671475303445,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"},"user_tz":300},"id":"0qSyxcU6GVf4","outputId":"3713bbef-765c-4d05-ddde-ee2730f8ff29"},"outputs":[{"output_type":"stream","name":"stdout","text":["22 166\n","22 166\n"]}],"source":["# Build a dataset\n","jobs_train, jobs_test = build_datasets()\n","print(len(jobs_train[i][0]), len(jobs_train[i][1]))\n","print(len(jobs_test[i][0]), len(jobs_test[i][1]))\n","\n","# Buid a dataloader\n","train_batch_size = 128\n","dataloader_train, dataloader_test = build_dataloaders(jobs_train, jobs_test, train_batch_size)"]},{"cell_type":"markdown","metadata":{"id":"uyfu99yJLV2Y"},"source":["# Todo: Define model"]},{"cell_type":"code","source":["import torch.nn as nn\n","import random\n","\n","class Encoder(nn.Module):\n","    def __init__(self, input_dim: int, emb_dim: int, hid_dim: int, n_layers: int, dropout: float):\n","        super().__init__()\n","        self.input_dim = input_dim # Input vocab size\n","        self.emb_dim = emb_dim # Embedding layer's dimension\n","        self.hid_dim = hid_dim # LSTM Hidden/Cell state's dimension\n","        self.n_layers = n_layers # Number of LSTM layers\n","        self.dropout = dropout # Dropout for the LSTM layer\n","\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n","\n","    def forward(self, enc_input: torch.LongTensor): # feature length * batch size\n","        embedding = self.embedding(enc_input) # [feature len, batch size, emb dim]\n","        outputs, (hidden, cell) = self.lstm(embedding) # outputs -> [feature length, batch size, hidden dim * n directions]\n","\n","        # LSTM hidden stateï¼Œ LSTM cell state\n","        return outputs, hidden, cell #  [n layers * n directions, batch size, hidden dim], [n layers * n directions, batch size, hidden dim]"],"metadata":{"id":"Wgyv9SZnKHt2","executionInfo":{"status":"ok","timestamp":1671475303445,"user_tz":300,"elapsed":6,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Use gpu or cpu \n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Pre-define parameters\n","input_dim, output_dim = len(input_vocab), len(query_vocab)\n","emb_dim = 128\n","hidden_dim = 256\n","num_layers = 2\n","dropout_ratio = 0.1\n","\n","# Extract one batch from the dataloader_test\n","input, query = next(iter(dataloader_test))\n","print(\"input's shape = {}, query's shape = {}\".format(input.shape, query.shape))\n","\n","# Check the dimension of encoder's output\n","encoder = Encoder(input_dim, emb_dim, hidden_dim, num_layers, dropout_ratio).to(device)\n","_, hidden, cell = encoder(input.to(device))\n","print(encoder)\n","print(\"hidden's shape = {}, cell's shape = {}\".format(hidden.shape, cell.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wk3CZzcGKUin","executionInfo":{"status":"ok","timestamp":1671475312160,"user_tz":300,"elapsed":8720,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}},"outputId":"2269a7d7-04b2-44e4-e401-48ccc3a845a6"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["input's shape = torch.Size([22, 1]), query's shape = torch.Size([166, 1])\n","Encoder(\n","  (embedding): Embedding(229, 128)\n","  (lstm): LSTM(128, 256, num_layers=2, dropout=0.1)\n",")\n","hidden's shape = torch.Size([2, 1, 256]), cell's shape = torch.Size([2, 1, 256])\n"]}]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim: int, emb_dim: int, hid_dim: int, n_layers: int, dropout: float):\n","        super().__init__()\n","        self.output_dim = output_dim # Query vocab size.\n","        self.emb_dim = emb_dim # Embedding layer's dimension\n","        self.hid_dim = hid_dim # LSTM Hidden/Cell state's dimension\n","        self.n_layers = n_layers # Number of LSTM layers\n","        self.dropout = dropout # Dropout for the LSTM layer\n","\n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        self.lstm = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n","        self.out = nn.Linear(hid_dim, output_dim)\n","\n","    def forward(self, dec_input: torch.LongTensor, hidden: torch.FloatTensor, cell: torch.FloatTensor): # Batched tokenized source sentence of shape [batch size].\n","        embedding = self.embedding(dec_input) # [1, batch size, emb dim]\n","        outputs, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n","        prediction = self.out(outputs.squeeze(0))\n","        return prediction, hidden, cell # [batch size, output dim], [n layers * n directions, batch size, hidden dim], [n layers * n directions, batch size, hidden dim]\n"],"metadata":{"id":"1VpIaAaUKHZj","executionInfo":{"status":"ok","timestamp":1671475312160,"user_tz":300,"elapsed":21,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Check the dimension of decoder's output\n","decoder = Decoder(output_dim, emb_dim, hidden_dim, num_layers, dropout_ratio).to(device)\n","prediction, hidden, cell = decoder(query.to(device), hidden, cell)\n","print(decoder)\n","print(\"prediction's shape = {}, hidden's shape = {}, cell's shape = {}\".format(prediction.shape, hidden.shape, cell.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41qPLpbzKfD3","executionInfo":{"status":"ok","timestamp":1671475312161,"user_tz":300,"elapsed":20,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}},"outputId":"e85efe4e-809f-4f95-a065-346f5b5cf17f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Decoder(\n","  (embedding): Embedding(503, 128)\n","  (lstm): LSTM(128, 256, num_layers=2, dropout=0.1)\n","  (out): Linear(in_features=256, out_features=503, bias=True)\n",")\n","prediction's shape = torch.Size([166, 1, 503]), hidden's shape = torch.Size([2, 1, 256]), cell's shape = torch.Size([2, 1, 256])\n"]}]},{"cell_type":"code","execution_count":13,"metadata":{"id":"3kcUungYLOSp","executionInfo":{"status":"ok","timestamp":1671475312162,"user_tz":300,"elapsed":18,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}}},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder: Encoder, decoder: Decoder, device: torch.device):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","\n","    def forward(self, input_batch: torch.LongTensor, query_batch: torch.LongTensor, teacher_forcing_ratio: float=1.0):\n","\n","        query_size, batch_size = query_batch.shape\n","        query_vocab_size = self.decoder.output_dim\n","\n","        # Initializae a tensor to store decoder's output\n","        outputs = torch.zeros(query_size, batch_size, query_vocab_size).to(self.device)\n","\n","        # Last hidden & cell state of the encoder is used as the decoder's initial hidden state\n","        _, hidden, cell = self.encoder(input_batch)\n","\n","        # Predict token by token\n","        query = query_batch[0].unsqueeze(0) # <S>, start of the sentence\n","        for i in range(1, query_size):\n","            pred, hidden, cell = self.decoder(query, hidden, cell)\n","            outputs[i] = pred\n","\n","            # apply teacher force\n","            best_pred = pred.argmax(1)\n","            query = query_batch[i] if random.random() < teacher_forcing_ratio else best_pred\n","            query = query.unsqueeze(0)\n","\n","        return outputs\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfTqVRf4DVGk","executionInfo":{"status":"ok","timestamp":1671475312162,"user_tz":300,"elapsed":18,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}},"outputId":"2e0859a7-0ada-43b7-bb4e-27ee33fc27ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(229, 128)\n","    (lstm): LSTM(128, 256, num_layers=2, dropout=0.1)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(503, 128)\n","    (lstm): LSTM(128, 256, num_layers=2, dropout=0.1)\n","    (out): Linear(in_features=256, out_features=503, bias=True)\n","  )\n",")\n","torch.Size([166, 1, 503])\n"]}],"source":["# Check seq2seq\n","seq2seq = Seq2Seq(encoder, decoder, device).to(device)\n","outputs = seq2seq(input.to(device), query.to(device))\n","print(seq2seq)\n","print(outputs.shape)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"YETsoUlaKrc0","executionInfo":{"status":"ok","timestamp":1671475312163,"user_tz":300,"elapsed":16,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}}},"outputs":[],"source":["def create_model(input_dim, output_dim, device):\n","  emb_dim = 128\n","  hidden_dim = 256\n","  num_layers = 2\n","  dropout_ratio = 0.1\n","\n","  encoder = Encoder(input_dim, emb_dim, hidden_dim, num_layers, dropout_ratio)\n","  decoder = Decoder(output_dim, emb_dim, hidden_dim, num_layers, dropout_ratio)\n","  seq2seq = Seq2Seq(encoder, decoder, device).to(device)\n","\n","  return seq2seq"]},{"cell_type":"markdown","metadata":{"id":"q2lqWX_VLe_W"},"source":["# Todo: Training and testing loops"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"8sPIFdxPHqUG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671475312163,"user_tz":300,"elapsed":14,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}},"outputId":"7f54c600-a250-4795-a3dd-a502c34703de"},"outputs":[{"output_type":"stream","name":"stdout","text":["0 14 502\n"]}],"source":["QUERY_SOS_INDEX = query_word2idx['<s>']\n","QUERY_EOS_INDEX = query_word2idx['</s>']\n","QUERY_PAD_INDEX = query_word2idx['<PAD>']\n","\n","print(QUERY_SOS_INDEX, QUERY_EOS_INDEX, QUERY_PAD_INDEX)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"0Q6VX5c5LzcA","executionInfo":{"status":"ok","timestamp":1671475557080,"user_tz":300,"elapsed":498,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}}},"outputs":[],"source":["from timeit import default_timer as timer\n","def train(model, train_dataloader, num_epochs, device=\"cuda\"):\n","\n","  # Initialize a model\n","  loss_fn = torch.nn.CrossEntropyLoss(ignore_index=QUERY_PAD_INDEX)\n","  optimizer = torch.optim.Adam(model.parameters(), lr=0.005) \n","  \n","  def init_weights(m):\n","    for name, param in m.named_parameters():\n","        nn.init.normal_(param.data, mean=0, std=0.01)        \n","  model.apply(init_weights)\n","  \n","  # Training loop\n","  for epoch in range(num_epochs):\n","    start_time = timer()\n","\n","    model.train()\n","    epoch_loss = 0\n","\n","    # Iterate the batches\n","    for input, query in train_dataloader:\n","      # Process the data in specified device\n","      input, query = input.to(device), query.to(device)\n","\n","      # Clear the gradient\n","      optimizer.zero_grad() \n","\n","      # Get logits and loss\n","      logits = model(input, query)\n","\n","      # Compute loss\n","      loss = loss_fn(logits[1:].view(-1, logits.shape[-1]), query[1:].view(-1))\n","\n","      # Update parameters\n","      loss.backward()\n","      optimizer.step()\n","\n","      # Update the loss\n","      epoch_loss += loss.item()\n","    \n","    end_time = timer()\n","\n","    train_loss = epoch_loss / len(train_dataloader)\n","    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n","\n","  return model\n"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"Z57MMyn4L1eb","executionInfo":{"status":"ok","timestamp":1671475503023,"user_tz":300,"elapsed":319,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}}},"outputs":[],"source":["def evaluate(model, dataloader, device=\"cuda\"):\n","  model.eval()\n","  softmax = nn.Softmax(dim=0)\n","  cnt, total = 0, 0 \n","  flag = 1\n","  with torch.no_grad():\n","      for input, query in dataloader:\n","        input, query = input.to(device), query.to(device)\n","        # logits = softmax(model(input, query, teacher_forcing_ratio=0))\n","        logits = model(input, query, teacher_forcing_ratio=0)\n","        pred = torch.argmax(logits, dim=-1) # Find index with largest possibility for each row\n","\n","        predw = []\n","        querw = []\n","        for p, q in zip(pred[1:].squeeze(), query[1:].squeeze()):\n","          if q.item() == QUERY_EOS_INDEX: # no need to count the paddings after </s>\n","            break\n","          \n","          if p == q:\n","            cnt += 1\n","          \n","          total += 1\n","\n","          predw.append(query_idx2word[p.item()])\n","          querw.append(query_idx2word[q.item()])\n","\n","        if flag <= 10:\n","          print(\" \".join(predw))\n","          print(\" \".join(querw))\n","        flag += 1\n","\n","  acc = cnt / total\n","  print(\"cnt={}, total={}\".format(cnt, total))\n","  return acc"]},{"cell_type":"markdown","metadata":{"id":"fOkicC3yLkfv"},"source":["# Run this!\n","\n","Your outputs should look something like this (not exactly the same numbers, just in a similar ballpark and format).\n","\n","```\n","Epoch: 1, Train loss: 4.590\n","Epoch: 2, Train loss: 1.871\n","Epoch: 3, Train loss: 1.424\n","...\n","Test Accuracy: 0.5195115804672241\n","```\n","\n"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":142655,"status":"ok","timestamp":1671475709461,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"},"user_tz":300},"id":"0qSnLCPeiI1N","outputId":"795439a1-ac7f-44fb-c8de-154fd8297368"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Train loss: 3.435, Epoch time = 4.739s\n","Epoch: 1, Train loss: 2.778, Epoch time = 4.666s\n","Epoch: 2, Train loss: 2.674, Epoch time = 4.668s\n","Epoch: 3, Train loss: 2.613, Epoch time = 4.714s\n","Epoch: 4, Train loss: 2.568, Epoch time = 4.731s\n","Epoch: 5, Train loss: 2.558, Epoch time = 4.759s\n","Epoch: 6, Train loss: 2.379, Epoch time = 5.282s\n","Epoch: 7, Train loss: 2.105, Epoch time = 4.714s\n","Epoch: 8, Train loss: 1.871, Epoch time = 4.797s\n","Epoch: 9, Train loss: 1.657, Epoch time = 5.157s\n","Epoch: 10, Train loss: 1.518, Epoch time = 4.654s\n","Epoch: 11, Train loss: 1.371, Epoch time = 4.678s\n","Epoch: 12, Train loss: 1.269, Epoch time = 4.709s\n","Epoch: 13, Train loss: 1.195, Epoch time = 4.586s\n","Epoch: 14, Train loss: 1.126, Epoch time = 4.569s\n","Epoch: 15, Train loss: 1.084, Epoch time = 4.652s\n","Epoch: 16, Train loss: 1.038, Epoch time = 4.660s\n","Epoch: 17, Train loss: 0.973, Epoch time = 4.659s\n","Epoch: 18, Train loss: 0.934, Epoch time = 4.681s\n","Epoch: 19, Train loss: 0.872, Epoch time = 4.643s\n","Epoch: 20, Train loss: 0.832, Epoch time = 4.656s\n","Epoch: 21, Train loss: 0.800, Epoch time = 4.837s\n","Epoch: 22, Train loss: 0.762, Epoch time = 4.629s\n","Epoch: 23, Train loss: 0.784, Epoch time = 4.804s\n","Epoch: 24, Train loss: 0.724, Epoch time = 4.661s\n","Epoch: 25, Train loss: 0.717, Epoch time = 4.709s\n","Epoch: 26, Train loss: 0.723, Epoch time = 4.574s\n","Epoch: 27, Train loss: 0.679, Epoch time = 5.363s\n","Epoch: 28, Train loss: 0.652, Epoch time = 4.598s\n","Epoch: 29, Train loss: 0.668, Epoch time = 4.699s\n"]}],"source":["def main():\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    jobs_train, jobs_test = build_datasets()\n","    dataloader_train, dataloader_test = build_dataloaders(jobs_train, jobs_test, train_batch_size=20)\n","    model = create_model(input_dim = len(input_vocab), output_dim = len(query_vocab), device=device)\n","    model = train(model, dataloader_train, num_epochs=30, device=device)\n","    # test_accuracy = evaluate(model, dataloader_test, device=device)\n","    # print(f'Test Accuracy: {test_accuracy}')\n","    return model\n","\n","m = main()\n"]},{"cell_type":"code","source":["test_accuracy = evaluate(m, dataloader_test, device=device)\n","print(f'Test Accuracy: {test_accuracy}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4ckSNvSqNFG","executionInfo":{"status":"ok","timestamp":1671475720538,"user_tz":300,"elapsed":6794,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}},"outputId":"73f6bad5-c7c1-4c82-e366-3615e9925238"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["answer ( a , ( job ( a ) , loc ( a , l ) , const ( l , ' austin ' ) , language ( a ,\n","answer ( <UNK> , ( job ( <UNK> ) , area ( <UNK> , <UNK> ) , const ( <UNK> , ' tcp / ip ' ) ) ) )\n","answer ( a , ( job ( a ) , loc ( a , b ) , const ( b , ' austin ' ) , language ( a ,\n","answer ( <UNK> , ( job ( <UNK> ) , language ( <UNK> , <UNK> ) , const ( <UNK> , ' c + + ' ) ) ) )\n","answer ( a , ( job ( a ) , loc ( a , l ) , const ( l , ' austin ' ) , language ( a , l ) , const ( c , ' austin ' ) , platform ( a , p ) , const\n","answer ( a , ( job ( a ) , loc ( a , b ) , const ( b , ' seattle ' ) , \\ + ( ( company ( a , n ) , const ( n , ' microsoft ' ) ) ) ) ) )\n","answer ( a , ( job ( a ) , loc ( a , l ) , const ( l , ' austin ' ) , language ( a , l ) , const ( c , ' austin ' ) , platform ( a , p ) , const ( p , ' unix ' ) ,\n","answer ( a , ( job ( a ) , loc ( a , h ) , const ( h , ' houston ' ) , req_deg ( a , d ) , const ( d , ' bscs ' ) , req_exp ( a , e ) , const ( e , 1 ) ) ) )\n","answer ( a , ( job ( a ) , loc ( a , l ) , const ( l , ' austin ' ) , language (\n","answer ( <UNK> , ( job ( <UNK> ) , platform ( <UNK> , <UNK> ) , const ( <UNK> , ' novell ' ) ) ) )\n","answer ( a , ( job ( a ) , loc ( a , l ) , const ( l , ' austin ' ) , language ( a\n","answer ( <UNK> , ( job ( <UNK> ) , loc ( <UNK> , <UNK> ) , const ( <UNK> , ' san antonio ' ) ) ) )\n","answer ( a , ( job ( a ) , loc ( a , l ) , const ( l , ' austin ' ) , language ( a , l ) ,\n","answer ( a , ( job ( a ) , \\ + req_deg ( a ) , language ( a , p ) , const ( p , perl ) ) ) )\n","answer ( a , ( job ( a ) , loc ( a , b ) , const ( b , ' austin ' ) , language (\n","answer ( <UNK> , ( job ( <UNK> ) , language ( <UNK> , <UNK> ) , const ( <UNK> , ' sql ' ) ) ) )\n","answer ( a , ( job ( a ) , loc ( a , b ) , const ( a , ' austin ' ) , language ( a , l ) , const ( c , ' austin ' ) ) ) ) </s> const ( a , ' bscs ' ) ) ) ) </s> const ( a , ' bscs ' ) ) ) ) </s> const ( a , ' bscs ' ) ) ) ) </s> const ( a ,\n","answer ( j , ( job ( j ) , salary_greater_than ( j , <UNK> , <UNK> ) , language ( j , g ) , const ( g , ' java ' ) , company ( j , c ) , const ( c , ' apple ' ) , area ( j , a ) , const ( a , ' internet ' ) , loc ( j , l ) , const ( l , ' california ' ) ) ) )\n","answer ( a , ( job ( a ) , loc ( a , l ) , const ( l , ' austin ' ) , language ( a , l ) , const ( c , ' austin ' ) , platform (\n","answer ( j , ( job ( j ) , platform ( j , p ) , const ( p , ' novell ' ) , area ( j , a ) , const ( a , ' internet ' ) ) ) )\n","cnt=3139, total=5943\n","Test Accuracy: 0.5281844186437826\n"]}]}],"metadata":{"colab":{"collapsed_sections":["_hfJFfYRSFBV","RCKjb4HsMKw-"],"provenance":[{"file_id":"1JlmczouOxFfNDH1KvYqtn2Txz8lEGemO","timestamp":1670640957717},{"file_id":"1xhajezR-zQD6JnGlPNOEcDHw3Q18hAdE","timestamp":1670442695449}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}
{"cells":[{"cell_type":"markdown","metadata":{"id":"_hfJFfYRSFBV"},"source":["# Data Pre-processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6rE5Aih1yY_i"},"outputs":[],"source":["# data from https://www.cs.utexas.edu/~ai-lab/pubs/cocktail-ecml-01.pdf\n","# and https://www.cs.utexas.edu/users/ml/nldata.html \n","\n","import regex as re\n","from nltk.stem import SnowballStemmer\n","from urllib.request import urlopen\n","from contextlib import closing\n","from sklearn.model_selection import train_test_split\n","\n","ss = SnowballStemmer('english')\n","\n","inputs = []\n","queries = []\n","\n","# Extract the raw data from the URL\n","with closing(urlopen('ftp://ftp.cs.utexas.edu/pub/mooney/nl-ilp-data/jobsystem/jobqueries640')) as r:\n","  for line in r.readlines():\n","    line = line.decode('utf-8')\n","    input, query = line.lower().split('],')\n","\n","    # parse input. lowercase, stem with nltk, add <s>\n","    input = input[7:-2].split(',')\n","    input = [ss.stem(x) for x in input]\n","    inputs.append(input)\n","\n","    # parse query \n","    query = query.strip('.\\n')\n","    # https://stackoverflow.com/questions/43092970/tokenize-by-using-regular-expressions-parenthesis\n","    query = re.findall(r\"\\w+(?:'\\w+)?|[^\\w\\s]\", query)\n","    query = [\"<s>\"] + query + [\"</s>\"]\n","    queries.append(query)\n","\n","# do train test split of 500 training and 140 test instances\n","inputs_train, inputs_test, queries_train, queries_test = train_test_split(inputs, queries, test_size=140, random_state=8)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1671485724157,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"},"user_tz":300},"id":"rqr9r3NTI-ab","outputId":"89981da7-ba5a-4214-c0bd-d6d455a44497"},"outputs":[{"output_type":"stream","name":"stdout","text":["['what', 'job', 'are', 'there', 'use', 'tcl/tk']\n","['<s>', 'answer', '(', '_1973', ',', '(', 'job', '(', '_1973', ')', ',', 'language', '(', '_1973', ',', '_1990', ')', ',', 'const', '(', '_1990', ',', \"'\", 'tcl', '/', 'tk', \"'\", ')', ')', ')', ')', '</s>']\n","['show', 'me', 'the', 'job', 'use', 'c++', 'that', 'requir', 'a', 'bscs', 'but', 'desir', 'a', 'mscs']\n","['<s>', 'answer', '(', 'c', ',', '(', 'job', '(', 'c', ')', ',', 'language', '(', 'c', ',', 'l', ')', ',', 'const', '(', 'l', ',', \"'\", 'c', '+', '+', \"'\", ')', ',', 'req_deg', '(', 'c', ',', 'd', ')', ',', 'const', '(', 'd', ',', \"'\", 'bscs', \"'\", ')', ',', 'des_deg', '(', 'c', ',', 'e', ')', ',', 'const', '(', 'e', ',', \"'\", 'mscs', \"'\", ')', ')', ')', ')', '</s>']\n","['what', 'job', 'are', 'there', 'for', 'a', 'network', 'specialist']\n","['<s>', 'answer', '(', '_3359', ',', '(', 'job', '(', '_3359', ')', ',', 'area', '(', '_3359', ',', '_3378', ')', ',', 'const', '(', '_3378', ',', \"'\", 'networking', \"'\", ')', ')', ')', ')', '</s>']\n","['give', 'me', 'the', 'job', 'in', 'visual', 'c++']\n","['<s>', 'answer', '(', '_5851', ',', '(', 'job', '(', '_5851', ')', ',', 'language', '(', '_5851', ',', '_5868', ')', ',', 'const', '(', '_5868', ',', \"'\", 'visual', 'c', '+', '+', \"'\", ')', ')', ')', ')', '</s>']\n","['list', 'job', 'requir', 'bsee']\n","['<s>', 'answer', '(', '_7125', ',', '(', 'job', '(', '_7125', ')', ',', 'req_deg', '(', '_7125', ',', '_7138', ')', ',', 'const', '(', '_7138', ',', \"'\", 'bsee', \"'\", ')', ')', ')', ')', '</s>']\n"]}],"source":["# Check the first 5 raw data\n","for i in range(5):\n","  print(inputs_train[i])\n","  print(queries_train[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KEG4r-BpA3mH"},"outputs":[],"source":["from collections import Counter\n","\n","input_vocab = Counter()\n","for l in inputs_train:\n","  input_vocab.update(l)\n","\n","# Update the input word2idx and idx2word\n","input_word2idx = {}\n","for w, c in input_vocab.items():\n","  if c >= 2:\n","    input_word2idx[w] = len(input_word2idx)\n","input_word2idx['<UNK>'] = len(input_word2idx) # Set the index for unkown word\n","input_word2idx['<PAD>'] = len(input_word2idx) # Set the index for padding word\n","input_idx2word = {i:word for word,i in input_word2idx.items()} # Build the idx2word based on word2idx\n","\n","input_vocab = list(input_word2idx.keys()) \n","\n","# Update the query word2idx and idx2word\n","query_vocab = Counter()\n","for q in queries_train:\n","  query_vocab.update(q)\n","query_vocab['<UNK>'] = 0 \n","query_vocab['<PAD>'] = 0\n","query_idx2word = {i:word for i, word in enumerate(query_vocab.keys())}\n","query_word2idx = {word:i for i, word in query_idx2word.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1671485724158,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"},"user_tz":300},"id":"0c_RivDrE0rY","outputId":"e8d1c23b-fc24-4b97-f68e-2abf8a4e3c78"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('what', 0), ('job', 1), ('are', 2), ('there', 3), ('use', 4), ('show', 5), ('me', 6), ('the', 7), ('c++', 8), ('that', 9)]\n","[(0, 'what'), (1, 'job'), (2, 'are'), (3, 'there'), (4, 'use'), (5, 'show'), (6, 'me'), (7, 'the'), (8, 'c++'), (9, 'that')]\n","[('<s>', 0), ('answer', 1), ('(', 2), ('_1973', 3), (',', 4), ('job', 5), (')', 6), ('language', 7), ('_1990', 8), ('const', 9)]\n","[(0, '<s>'), (1, 'answer'), (2, '('), (3, '_1973'), (4, ','), (5, 'job'), (6, ')'), (7, 'language'), (8, '_1990'), (9, 'const')]\n"]}],"source":["# Check the first 5 word2idx, idx2word\n","print(list(input_word2idx.items())[:10])\n","print(list(input_idx2word.items())[:10])\n","print(list(query_word2idx.items())[:10])\n","print(list(query_idx2word.items())[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6NH1EXAqDgnR"},"outputs":[],"source":["# Feature Construction\n","inputs_train_tokens = [[input_word2idx.get(w, input_word2idx['<UNK>']) for w in l] for l in inputs_train]\n","inputs_test_tokens = [[input_word2idx.get(w, input_word2idx['<UNK>']) for w in l] for l in inputs_test]\n","\n","queries_train_tokens = [[query_word2idx.get(w, query_word2idx['<UNK>']) for w in l] for l in queries_train]\n","queries_test_tokens = [[query_word2idx.get(w, query_word2idx['<UNK>']) for w in l] for l in queries_test]\n","\n","# Add paddings to each feature\n","def pad(input_seq, max_len, pad_token_idx):\n","  input_seq = input_seq[:max_len]\n","  padded_seq = input_seq + (max_len - len(input_seq)) * [pad_token_idx]\n","  return padded_seq\n","\n","inputs_max_target_len = max([len(i) for i in inputs_train_tokens])\n","inputs_train_tokens = [pad(i, inputs_max_target_len, input_word2idx['<PAD>']) for i in inputs_train_tokens]\n","inputs_test_tokens = [pad(i, inputs_max_target_len, input_word2idx['<PAD>']) for i in inputs_test_tokens]\n","\n","queries_max_target_len = int(max([len(i) for i in queries_train_tokens]) * 1.5) \n","queries_train_tokens = [pad(i, queries_max_target_len, query_word2idx['<PAD>']) for i in queries_train_tokens]\n","queries_test_tokens = [pad(i, queries_max_target_len, query_word2idx['<PAD>']) for i in queries_test_tokens]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671485724398,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"},"user_tz":300},"id":"Y_WHbv05FzfS","outputId":"7d03ed04-2e4d-4d56-ed3a-d8bf9e9a67ff"},"outputs":[{"output_type":"stream","name":"stdout","text":["501 22 [0, 1, 2, 3, 4, 227, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228]\n","140 22 [2, 3, 48, 1, 20, 227, 227, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228, 228]\n","501 166 [0, 1, 2, 3, 4, 2, 5, 2, 3, 6, 4, 7, 2, 3, 4, 8, 6, 4, 9, 2, 8, 4, 10, 11, 12, 13, 10, 6, 6, 6, 6, 14, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502]\n","140 166 [0, 1, 2, 501, 4, 2, 5, 2, 501, 6, 4, 25, 2, 501, 4, 501, 6, 4, 9, 2, 501, 4, 10, 206, 12, 207, 10, 6, 6, 6, 6, 14, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502, 502]\n"]}],"source":["# Check the first 5 train, test tokens\n","# Print the number of tokens, feature length, the first feature\n","print(len(inputs_train_tokens), len(inputs_train_tokens[0]), inputs_train_tokens[0])\n","print(len(inputs_test_tokens), len(inputs_test_tokens[0]), inputs_test_tokens[0])\n","print(len(queries_train_tokens), len(queries_train_tokens[0]), queries_train_tokens[0])\n","print(len(queries_test_tokens), len(queries_test_tokens[0]), queries_test_tokens[0])"]},{"cell_type":"markdown","metadata":{"id":"RCKjb4HsMKw-"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PginNNZ2sqqN"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader, default_collate\n","\n","class JobsDataset(Dataset):\n","  def __init__(self, inputs, queries):\n","    self.inputs = inputs\n","    self.queries = queries\n","\n","  def __len__(self):\n","      return len(self.inputs)\n","\n","  def __getitem__(self, idx):\n","      return self.inputs[idx], self.queries[idx]\n","\n","def build_datasets():\n","  jobs_train = JobsDataset(inputs=inputs_train_tokens, queries=queries_train_tokens)\n","  jobs_test = JobsDataset(inputs=inputs_test_tokens, queries=queries_test_tokens)\n","  return jobs_train, jobs_test\n","\n","def collate(batch):\n","  src, tgt = default_collate(batch)\n","  return torch.stack(src), torch.stack(tgt)\n","\n","def build_dataloaders(dataset_train, dataset_test, train_batch_size):\n","  dataloader_train = DataLoader(dataset_train, batch_size=train_batch_size, shuffle=True, collate_fn=collate)\n","  dataloader_test = DataLoader(dataset_test, batch_size=1, shuffle=False, collate_fn=collate)\n","  return dataloader_train, dataloader_test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1671485725126,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"},"user_tz":300},"id":"0qSyxcU6GVf4","outputId":"d4e77315-dbda-43b0-d39f-d828f4e9de7a"},"outputs":[{"output_type":"stream","name":"stdout","text":["22 166\n","22 166\n"]}],"source":["# Build a dataset\n","jobs_train, jobs_test = build_datasets()\n","print(len(jobs_train[i][0]), len(jobs_train[i][1]))\n","print(len(jobs_test[i][0]), len(jobs_test[i][1]))\n","\n","# Buid a dataloader\n","train_batch_size = 128\n","dataloader_train, dataloader_test = build_dataloaders(jobs_train, jobs_test, train_batch_size)"]},{"cell_type":"markdown","metadata":{"id":"uyfu99yJLV2Y"},"source":["# Todo: Define model"]},{"cell_type":"markdown","source":["## Encoder Implementation"],"metadata":{"id":"FB0cl8Zzu97p"}},{"cell_type":"code","source":["import torch.nn as nn\n","import random\n","\n","class Encoder(nn.Module):\n","    def __init__(self, input_dim: int, emb_dim: int, hid_dim: int, n_layers: int):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(num_embeddings=input_dim, embedding_dim=emb_dim)\n","        self.lstm = nn.LSTM(input_size=emb_dim, hidden_size=hid_dim, num_layers=n_layers)\n","\n","    def forward(self, enc_input: torch.LongTensor): \n","        '''\n","        Input: enc_input -> [feature length, batch size]\n","        Output: outputs  -> [feature length, batch size, hid dim]\n","                hidden   -> [n layers, batch size, hid dim]\n","                cell     -> [n layers, batch size, hid dim]\n","        '''\n","        embedding = self.embedding(enc_input) # [feature length, batch size, emb dim]\n","        outputs, (hidden, cell) = self.lstm(embedding)\n","\n","        return outputs, hidden, cell "],"metadata":{"id":"Wgyv9SZnKHt2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use gpu or cpu \n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Pre-define parameters\n","input_dim, output_dim = len(input_vocab), len(query_vocab)\n","emb_dim = 128\n","hidden_dim = 256\n","num_layers = 2\n","\n","# Extract one batch from the dataloader_test\n","input, query = next(iter(dataloader_test))\n","print(\"input's shape = {}, query's shape = {}\".format(input.shape, query.shape))\n","\n","# Check the dimension of encoder's output\n","encoder = Encoder(input_dim, emb_dim, hidden_dim, num_layers).to(device)\n","enc_outputs, hidden, cell = encoder(input.to(device))\n","print(encoder)\n","print(\"enc_outputs's shape = {}, hidden's shape = {}, cell's shape = {}\".format(enc_outputs.shape, hidden.shape, cell.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wk3CZzcGKUin","executionInfo":{"status":"ok","timestamp":1671485729636,"user_tz":300,"elapsed":3592,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}},"outputId":"b3dc06d2-1b13-4dcd-f817-c1699df39f14"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["input's shape = torch.Size([22, 1]), query's shape = torch.Size([166, 1])\n","Encoder(\n","  (embedding): Embedding(229, 128)\n","  (lstm): LSTM(128, 256, num_layers=2)\n",")\n","enc_outputs's shape = torch.Size([22, 1, 256]), hidden's shape = torch.Size([2, 1, 256]), cell's shape = torch.Size([2, 1, 256])\n"]}]},{"cell_type":"markdown","source":["## Decoder Implementation"],"metadata":{"id":"xykM-Xj7vNW1"}},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim: int, emb_dim: int, hid_dim: int, n_layers: int):\n","        super().__init__()\n","\n","        self.hid_dim = hid_dim\n","        self.output_dim = output_dim\n","\n","        self.embedding = nn.Embedding(num_embeddings=output_dim, embedding_dim=emb_dim)\n","        self.lstm = nn.LSTM(input_size=emb_dim, hidden_size=hid_dim, num_layers=n_layers)\n","\n","    def forward(self, dec_input: torch.LongTensor, hidden: torch.FloatTensor, cell: torch.FloatTensor): \n","        '''\n","        Input: dec_input -> [feature length, batch size]\n","        Output: pred     -> [feature length, batch size, hid dim]\n","                hidden   -> [n layers, batch size, hid dim]\n","                cell     -> [n layers, batch size, hid dim]\n","        '''\n","        # dec_input = dec_input.unsqueeze(0)\n","        embedding = self.embedding(dec_input) # [1, batch size, emb dim]\n","        outputs, (hidden, cell) = self.lstm(embedding, (hidden, cell))\n","\n","        return outputs, hidden, cell \n"],"metadata":{"id":"1VpIaAaUKHZj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Check the dimension of decoder's output\n","decoder = Decoder(output_dim, emb_dim, hidden_dim, num_layers).to(device)\n","dec_outputs, hidden, cell = decoder(query.to(device), hidden, cell)\n","print(decoder)\n","print(\"dec_outputs's shape = {}, hidden's shape = {}, cell's shape = {}\".format(dec_outputs.shape, hidden.shape, cell.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"41qPLpbzKfD3","executionInfo":{"status":"ok","timestamp":1671485729637,"user_tz":300,"elapsed":9,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}},"outputId":"e0c60fe3-7432-4793-9737-a8a5686a421d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Decoder(\n","  (embedding): Embedding(503, 128)\n","  (lstm): LSTM(128, 256, num_layers=2)\n",")\n","dec_outputs's shape = torch.Size([166, 1, 256]), hidden's shape = torch.Size([2, 1, 256]), cell's shape = torch.Size([2, 1, 256])\n"]}]},{"cell_type":"code","source":["# Bahdanau Attention Mechanism\n","class Attention(nn.Module):\n","    def __init__(self, hid_dim: int, output_dim: int):\n","        super().__init__()\n","        \n","        self.w0 = nn.Linear(hid_dim, output_dim) # query vocab size\n","        self.w1 = nn.Linear(hid_dim, hid_dim)\n","        self.w2 = nn.Linear(hid_dim, hid_dim)\n","        self.tanh = nn.Tanh()\n","        self.softmax = nn.Softmax(dim=0)\n","\n","    def forward(self, hidden: torch.FloatTensor, enc_outputs: torch.FloatTensor, dec_outputs: torch.FloatTensor):\n","        #  the current hidden state of decoder\n","        h_l_t = hidden[-1] # [batch size, hid dim]\n","\n","        # Attention score with the k-th hidden state \n","        score = self.softmax(enc_outputs * h_l_t)\n","        \n","        # n = torch.exp(enc_outputs * h_l_t)\n","        # m = torch.sum(torch.exp(enc_outputs * h_l_t), dim=0) \n","        # score =  n / m\n","\n","        # Attention\n","        # Context vector is computed by weighted sum of the hidden vectors in the encoder\n","        context_vec = torch.sum(score * enc_outputs, dim=0) # [batch size, hid dim]\n","        output = self.w0(self.tanh(self.w1(dec_outputs) + self.w2(context_vec)))\n","\n","        return output"],"metadata":{"id":"5h72QpFoYgTj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["att_layer = Attention(hidden_dim, output_dim).to(device)\n","att_output = att_layer(hidden, enc_outputs, dec_outputs)\n","print(att_layer)\n","print(att_output.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-30ge3RLg1R9","executionInfo":{"status":"ok","timestamp":1671485729639,"user_tz":300,"elapsed":8,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}},"outputId":"11d7f0e1-cd0c-4f55-f019-15e07148ec07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Attention(\n","  (w0): Linear(in_features=256, out_features=503, bias=True)\n","  (w1): Linear(in_features=256, out_features=256, bias=True)\n","  (w2): Linear(in_features=256, out_features=256, bias=True)\n","  (tanh): Tanh()\n","  (softmax): Softmax(dim=0)\n",")\n","torch.Size([166, 1, 503])\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3kcUungYLOSp"},"outputs":[],"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder: Encoder, decoder: Decoder, attention: Attention, device: torch.device):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.attention = attention\n","        self.device = device\n","\n","    def forward(self, input_batch: torch.LongTensor, query_batch: torch.LongTensor, teacher_forcing_ratio: float=1.0):\n","\n","        query_size, batch_size = query_batch.shape\n","        query_vocab_size = self.decoder.output_dim\n","\n","        # Initializae a tensor to store decoder's output\n","        outputs = torch.zeros(query_size, batch_size, query_vocab_size).to(self.device) # [166, batch size, 503]\n","\n","        # Last hidden & cell state of the encoder is used as the decoder's initial hidden state\n","        enc_outputs, hidden, cell = self.encoder(input_batch)\n","\n","        # Predict token by token\n","        query = query_batch[0].unsqueeze(0) # <s>, start of the sentence\n","        for i in range(1, query_size):\n","            \n","            dec_outputs, hidden, cell = self.decoder(query, hidden, cell)\n","            outputs[i] = self.attention(hidden, enc_outputs, dec_outputs)\n","\n","            # apply teacher force\n","            best_pred = torch.argmax(outputs[i], dim=-1)\n","            teacher_forcing = random.random() < teacher_forcing_ratio\n","            query = query_batch[i].unsqueeze(0) if teacher_forcing else best_pred.unsqueeze(0)\n","\n","        return outputs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfTqVRf4DVGk","executionInfo":{"status":"ok","timestamp":1671485730562,"user_tz":300,"elapsed":9,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}},"outputId":"b20b9437-2356-4c3e-c43e-98d2deb85050"},"outputs":[{"output_type":"stream","name":"stdout","text":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(229, 128)\n","    (lstm): LSTM(128, 256, num_layers=2)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(503, 128)\n","    (lstm): LSTM(128, 256, num_layers=2)\n","  )\n","  (attention): Attention(\n","    (w0): Linear(in_features=256, out_features=503, bias=True)\n","    (w1): Linear(in_features=256, out_features=256, bias=True)\n","    (w2): Linear(in_features=256, out_features=256, bias=True)\n","    (tanh): Tanh()\n","    (softmax): Softmax(dim=0)\n","  )\n",")\n","outputs's shape = torch.Size([166, 1, 503])\n"]}],"source":["# Check seq2seq\n","seq2seq = Seq2Seq(encoder, decoder, att_layer, device).to(device)\n","outputs = seq2seq(input.to(device), query.to(device))\n","print(seq2seq)\n","print(\"outputs's shape = {}\".format(outputs.shape))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YETsoUlaKrc0"},"outputs":[],"source":["def create_model(input_dim, output_dim, device):\n","    emb_dim = 128\n","    hidden_dim = 256\n","    num_layers = 2\n","\n","    attention = Attention(hidden_dim, output_dim).to(device)\n","    encoder = Encoder(input_dim, emb_dim, hidden_dim, num_layers).to(device)\n","    decoder = Decoder(output_dim, emb_dim, hidden_dim, num_layers).to(device)\n","    seq2seq = Seq2Seq(encoder, decoder, attention, device).to(device)\n","\n","    return seq2seq"]},{"cell_type":"markdown","metadata":{"id":"q2lqWX_VLe_W"},"source":["# Todo: Training and testing loops"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8sPIFdxPHqUG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1671485730562,"user_tz":300,"elapsed":6,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"}},"outputId":"312f90a6-f09b-4890-eee5-9846f67cc9b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["0 14 502\n"]}],"source":["QUERY_SOS_INDEX = query_word2idx['<s>']\n","QUERY_EOS_INDEX = query_word2idx['</s>']\n","QUERY_PAD_INDEX = query_word2idx['<PAD>']\n","\n","print(QUERY_SOS_INDEX, QUERY_EOS_INDEX, QUERY_PAD_INDEX)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Q6VX5c5LzcA"},"outputs":[],"source":["from timeit import default_timer as timer\n","def train(model, train_dataloader, num_epochs, device=\"cuda\"):\n","\n","    loss_fn = torch.nn.CrossEntropyLoss(ignore_index=QUERY_PAD_INDEX).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.003)\n","    \n","    # Initialize parameters for the model\n","    # def init_weights(m):\n","    #     for name, param in m.named_parameters():\n","    #         nn.init.normal_(param.data, mean=0, std=0.01)        \n","    # model.apply(init_weights)\n","    \n","    # Training loop\n","    for epoch in range(num_epochs):\n","        start_time = timer()\n","\n","        model.train()\n","        epoch_loss = 0\n","\n","        # Iterate the batches\n","        for input, query in train_dataloader:\n","            # Process the data in specified device\n","            input, query = input.to(device), query.to(device)\n","            # print(input.shape, query.shape)\n","\n","            # Clear the gradient\n","            optimizer.zero_grad() \n","\n","            # Get logits and loss\n","            logits = model(input, query)\n","\n","            # Compute loss\n","            loss = loss_fn(logits[1:].reshape(-1, logits.shape[-1]), query[1:].reshape(-1))\n","\n","            # Update parameters\n","            loss.backward()\n","            optimizer.step()\n","\n","            # Update the loss\n","            epoch_loss += loss.item()\n","        \n","        end_time = timer()\n","\n","        train_loss = epoch_loss / len(train_dataloader)\n","        print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))\n","\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z57MMyn4L1eb"},"outputs":[],"source":["def evaluate(model, dataloader, device=\"cuda\"):\n","  model.eval()\n","  cnt, total = 0, 0 \n","  flag = 1\n","  with torch.no_grad():\n","      for input, query in dataloader:\n","        input, query = input.to(device), query.to(device)\n","        logits = model(input, query, teacher_forcing_ratio=0)\n","        pred = torch.argmax(logits, dim=-1) # Find index with largest possibility for each row\n","\n","        preds = []\n","        truth = []\n","        for p, q in zip(pred[1:].squeeze(), query[1:].squeeze()):\n","          if q.item() == QUERY_EOS_INDEX: # no need to count the paddings after </s>\n","            break\n","          \n","          if p == q:\n","            cnt += 1\n","          \n","          total += 1\n","\n","          preds.append(query_idx2word[p.item()])\n","          truth.append(query_idx2word[q.item()])\n","\n","        if flag <= 10:\n","          print(\"Predictions  \", \" \".join(preds))\n","          print(\"True Queries \", \" \".join(truth))\n","        flag += 1\n","\n","  acc = cnt / total\n","  # print(\"cnt={}, total={}\".format(cnt, total))\n","  return acc"]},{"cell_type":"markdown","metadata":{"id":"fOkicC3yLkfv"},"source":["# Run this!\n","\n","Your outputs should look something like this (not exactly the same numbers, just in a similar ballpark and format).\n","\n","```\n","Epoch: 1, Train loss: 4.590\n","Epoch: 2, Train loss: 1.871\n","Epoch: 3, Train loss: 1.424\n","...\n","Test Accuracy: 0.5195115804672241\n","```\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56141,"status":"ok","timestamp":1671485786700,"user":{"displayName":"Pinyuan Feng","userId":"00342977440202970625"},"user_tz":300},"id":"0qSnLCPeiI1N","outputId":"6d49ee9b-ba77-4129-b4b9-961bf707084e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0, Train loss: 4.059, Epoch time = 5.462s\n","Epoch: 1, Train loss: 2.982, Epoch time = 2.916s\n","Epoch: 2, Train loss: 2.856, Epoch time = 2.817s\n","Epoch: 3, Train loss: 2.698, Epoch time = 2.801s\n","Epoch: 4, Train loss: 2.404, Epoch time = 2.811s\n","Epoch: 5, Train loss: 2.086, Epoch time = 2.793s\n","Epoch: 6, Train loss: 1.807, Epoch time = 2.782s\n","Epoch: 7, Train loss: 1.584, Epoch time = 2.776s\n","Epoch: 8, Train loss: 1.422, Epoch time = 2.818s\n","Epoch: 9, Train loss: 1.314, Epoch time = 2.759s\n","Epoch: 10, Train loss: 1.227, Epoch time = 2.724s\n","Epoch: 11, Train loss: 1.157, Epoch time = 2.739s\n","Epoch: 12, Train loss: 1.099, Epoch time = 2.804s\n","Epoch: 13, Train loss: 1.043, Epoch time = 2.845s\n","Epoch: 14, Train loss: 0.999, Epoch time = 2.769s\n","Predictions   answer ( a , ( job ( a ) , loc ( a , c ) , const ( c , ' bscs ' ) ) ) ) </s> (\n","True Queries  answer ( <UNK> , ( job ( <UNK> ) , area ( <UNK> , <UNK> ) , const ( <UNK> , ' tcp / ip ' ) ) ) )\n","Predictions   answer ( a , ( job ( a ) , loc ( a , c ) , const ( c , ' bscs ' ) ) ) ) </s> (\n","True Queries  answer ( <UNK> , ( job ( <UNK> ) , language ( <UNK> , <UNK> ) , const ( <UNK> , ' c + + ' ) ) ) )\n","Predictions   answer ( a , ( job ( a ) , loc ( a , c ) , const ( c , ' bscs ' ) , language ( a , c ) , const ( c , ' bscs ' ) ) ) ) </s> loc ( a , c\n","True Queries  answer ( a , ( job ( a ) , loc ( a , b ) , const ( b , ' seattle ' ) , \\ + ( ( company ( a , n ) , const ( n , ' microsoft ' ) ) ) ) ) )\n","Predictions   answer ( a , ( job ( a ) , loc ( a , c ) , const ( c , ' bscs ' ) , language ( a , c ) , const ( c , ' bscs ' ) ) ) ) </s> loc ( a , c ) , const ( c , ' bscs\n","True Queries  answer ( a , ( job ( a ) , loc ( a , h ) , const ( h , ' houston ' ) , req_deg ( a , d ) , const ( d , ' bscs ' ) , req_exp ( a , e ) , const ( e , 1 ) ) ) )\n","Predictions   answer ( a , ( job ( a ) , loc ( a , c ) , const ( c , ' bscs ' ) ) ) )\n","True Queries  answer ( <UNK> , ( job ( <UNK> ) , platform ( <UNK> , <UNK> ) , const ( <UNK> , ' novell ' ) ) ) )\n","Predictions   answer ( a , ( job ( a ) , loc ( a , c ) , const ( c , ' bscs ' ) , language ( a\n","True Queries  answer ( <UNK> , ( job ( <UNK> ) , loc ( <UNK> , <UNK> ) , const ( <UNK> , ' san antonio ' ) ) ) )\n","Predictions   answer ( a , ( job ( a ) , loc ( a , c ) , const ( c , ' bscs ' ) , language ( a , c ) ,\n","True Queries  answer ( a , ( job ( a ) , \\ + req_deg ( a ) , language ( a , p ) , const ( p , perl ) ) ) )\n","Predictions   answer ( a , ( job ( a ) , loc ( a , c ) , const ( c , ' bscs ' ) ) ) )\n","True Queries  answer ( <UNK> , ( job ( <UNK> ) , language ( <UNK> , <UNK> ) , const ( <UNK> , ' sql ' ) ) ) )\n","Predictions   answer ( a , ( job ( a ) , loc ( a , c ) , const ( c , ' bscs ' ) , language ( a , c ) , const ( c , ' austin ' ) ) ) ) </s> ( ( a , job ( c ) , loc ( a , c ) , const ( c , ' austin ' ) ) ) ) </s> ( ( a , job ( c ) , loc ( a\n","True Queries  answer ( j , ( job ( j ) , salary_greater_than ( j , <UNK> , <UNK> ) , language ( j , g ) , const ( g , ' java ' ) , company ( j , c ) , const ( c , ' apple ' ) , area ( j , a ) , const ( a , ' internet ' ) , loc ( j , l ) , const ( l , ' california ' ) ) ) )\n","Predictions   answer ( a , ( job ( a ) , loc ( a , c ) , const ( c , ' bscs ' ) , language ( a , c ) , const ( c , ' bscs ' ) ) ) )\n","True Queries  answer ( j , ( job ( j ) , platform ( j , p ) , const ( p , ' novell ' ) , area ( j , a ) , const ( a , ' internet ' ) ) ) )\n","Test Accuracy: 0.5108531044926805\n"]}],"source":["def main():\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    jobs_train, jobs_test = build_datasets()\n","    dataloader_train, dataloader_test = build_dataloaders(jobs_train, jobs_test, train_batch_size=64)\n","    model = create_model(input_dim = len(input_vocab), output_dim = len(query_vocab), device=device)\n","    model = train(model, dataloader_train, num_epochs=15, device=device)\n","    test_accuracy = evaluate(model, dataloader_test, device=device)\n","    print(f'Test Accuracy: {test_accuracy}')\n","    return model\n","\n","m = main()\n"]},{"cell_type":"markdown","source":["\n","Google Drive link for the file: [**link**](https://colab.research.google.com/drive/1MTy_Yxjbwxil7rAentYmy3G6eLUT3m9J?usp=share_link)\n","\n","Video link: [**link**](https://drive.google.com/file/d/1vqQFgroQEtV3l_qL1ugmV8fSEI8HwcGg/view?usp=share_link)"],"metadata":{"id":"GhpVJO8sVCHS"}}],"metadata":{"colab":{"provenance":[{"file_id":"1JlmczouOxFfNDH1KvYqtn2Txz8lEGemO","timestamp":1670640957717},{"file_id":"1xhajezR-zQD6JnGlPNOEcDHw3Q18hAdE","timestamp":1670442695449}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}